# IMProv ( integrative modeling platform ) - Workflow (0.1)

This tutorial presents the step by step instructions to gather the data files 
and driver scripts needed to perform a MPI based IMP modeling job run. We demonstrate
these steps using the [PRC2 example project](https://integrativemodeling.org/) and explain how this was prepared 
using [MassSpecStudio](https://www.msstudio.ca/mss-improv/). The instructions cover running the job on two platforms:

* AWS: EC2 spot instance
* Compute Canada: Cedar cluster


#### PRC2 example project:  
* view imp_msstudio_init [on github, here.](https://github.com/pellst/imp_msstudio_init/tree/master/mss_out)
* then, download PRC2 example project, [here.](https://github.com/pellst/imp_msstudio_init/archive/master.zip)

Folders and files included in this project:
* **data**
   * em
   * fasta
   * hx
   * topo
   * xl
   * xtal  
* **imp_model**
   * readme_setup_cedar.txt
   * ConfigImp.yaml
   * mjob_run_cedar.sh
   * prep_hyper_imp_v2ux.py
   * ... and others 

The **data** folder contains various artifacts used to inform the integrative modeling.
The **imp_model** folder contains the driver python script and example yaml configuration for running the IMP modeling job.

## Fast Track:
* login to Cedar on Compute Canada and run these scripts in your user account
  * steps ...

* alternatively, login to your AWS account and from the Management Console perform these steps to launch an EC2 spot instance using the AMI for IMProv MPI jobs
  * steps ...
  * 

## Getting Started

These instructions will get you a copy of the project up and running for testing purposes. 
* how to setup new instance with python (3.x) and imp packages, together with sample project for PRC2.
  * initial run for modeling 100 frames ( approx. run duration is 15min ).
  * how to deploy the project on a live system for a short run. 
    * **runbook** for steps to setup software and data/driver scripts.
    * **playbook** for troubleshooting issues.
* clear distinction between platforms used ( Cedar vs AWS ) and steps to follow in each case.
  * for Cedar provide info on job scheduling with slurm and submitting multiple jobs ( clones ) for comparison.
  * for AWS the running of multiple jobs in parallel, requires launching separate instances.
* See **Deployment section** and considerations/details for running at scale.
  * in the deployment section provide guidance on running at scale, using the prepared AMI, incl. launching AMI with cloudformation or aws cli or via aws management console.
  * full job run for modeling 20,000 frames ( approx. run duration 10hrs )
  * for AWS, mention parallel-cluster and aws cli launch. Proof of Concept for use of the NFS folder /shared and symbolic link to python and imp
* 

**Cedar job run**

* link to Cedar preparation docs, account setup, login and run setup scripts 
* [Cedar HPC intro, on Compute Canada](https://www.westgrid.ca//support/quickstart/new_users)
* [Cedar login steps](https://docs.computecanada.ca/wiki/Connecting_with_MobaXTerm#Using_a_Key_Pair)
	* On Windows, various options:
	  * [MobaXTerm](https://docs.computecanada.ca/wiki/Connecting_with_MobaXTerm)
	  * [PuTTY](https://docs.computecanada.ca/wiki/Connecting_with_PuTTY)




**AWS job run**

* this requires running EC2 instances that are not eligible for the AWS Free Tier. While pricing varies, the typical cost for a 32cpu machine is under USD1.00 per hour.
* link to AWS account setup, default VPC launch of EC2 instance using either on-demand or spot instance.
* cloudcraft diagram of VPC, subnet, EC2 instance ( 16, 32 cpu options) , pricing ( on-demand, spot )
* cloudformation script
* prep AMI based on parallel-cluster image ( give version num ) - snapshot for golden image
* Amendment of cloudcraft script ( json or yaml style ) add AMI golden image to use
* IAM role for s3 upload of modeling results. 
  * TODO: add scripted copy of modeling output data to s3.
* option to upload a project content to s3 to store the project bundle generated by msstudio.
* 


In order to work with MPI ( message passing interface ) jobs such as this IMP example on AWS, we need to lay the groundwork. 
Use your existing AWS account or [signed up for AWS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html). 
Read the [EC2 Getting Started Guide](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html?r=1874). 
Familiarize yourself with how to start, access, and terminate different machine instances. 
We make use of on-demand instances for convenience in the preparation of the initial machine image 
as we explain the installation of the pre-requisite software ( on a t2.micro EC2 instance, in the AWS Free Tier).
Running EC2 spot instances is important, thereafter, in order to minimize costs for the testing of the MPI jobs.
AWS has a [research cloud program](https://pages.awscloud.com/rs/112-TZM-766/images/AWS_Research_Cloud_Program_Letter.pdf) which you may consider joining, [here](https://aws.amazon.com/government-education/research-and-technical-computing/research-cloud-program/). 

We make use of a number of shortcuts via scripted steps to facilitate the initial setup and accelerate the deployment processs.
At a later point we expand our explanation and provide further information or links to help fill in the knowledge gaps.

Initial setup assistance provided by the prep_step* shell scripts:
```
# make use of this gist to get the prep_step* shell scripts located here
# /shared/imp/imp_msstudio_init-master/mss_out/imp_model
curl -LOk https://gist.githubusercontent.com/pellst/9f7ad519133dae87f8f813b506b45aac/raw/aws_mss_prep_step1.sh 
chmod 755 aws_mss_prep_step1.sh 
./aws_mss_prep_step1.sh

# prepare anaconda install
#/shared/imp/imp_msstudio_init-master/mss_out/imp_model/aws_mss_prep_step2.sh
#/shared/imp/imp_msstudio_init-master/mss_out/imp_model/aws_mss_prep_step3.sh
```






### Prerequisites

The IMP job driver script runs with python 3.x and depends on the Python Modeling Interface (PMI)

The initial software installation of python with Anaconda and python packages for imp 
are included in the setup script. The individual steps are highlighted once again, hereafter.
```
#initial setup for PMI
Anaconda3\Library\bin\conda config --add channels salilab
Anaconda3\Library\bin\conda install imp scikit-learn matplotlib

#https://integrativemodeling.org/tutorials/rnapolii_stalk/
Anaconda3\Library\bin\conda install numpy scipy


#bring up Anaconda Prompt and run : activate base
#you can see envs available with: conda info --envs
#for example: this shows us that base is c:\apps\Anaconda3




```

```
Give examples
```

### Installing

A step by step series of examples that tell you how to get a development env running

The readme_setup_cedar.txt is a good place to start. This explains how to setup the example on Compute Canada's Cedar cluster.


```
Taken from the readme_setup_cedar.txt:


#### get the setup script and call it with the correct username as the first arg: 
~~~
curl -LOk https://gist.githubusercontent.com/pellst/4853822ea5ca74785af61d0ad39cf84d/raw/uoc_mss_prep_step1.sh
chmod 755 uoc_mss_prep_step1.sh
~~~

#### run the script uoc_mss_prep_step1.sh in order to get the sample folders setup
~~~
uoc_mss_prep_step1.sh tpells
~~~

#### in the folder scratch/imp/imp_msstudio_init-master/mss_out/imp_model, the following shell scripts are now available
~~~
            uoc_mss_prep_step1.sh
            uoc_mss_prep_step2.sh
            uoc_mss_prep_step3.sh
~~~
			
#### we can continue on to step2 to setup anaconda			
uoc_mss_prep_step2.sh


#### once anaconda has been setup we can bring in the imp module and others needed for the job run
uoc_mss_prep_step3.sh

#### the next step is to review the following:
#### located in scratch/imp/imp_msstudio_init-master/mss_out/imp_model
ConfigImp.yaml
mjob_run_cedar.sh

```

#### amend the sampling_frame in ConfigImp.yaml
sampling_frame: 100
* the cores is used for the ntasks-per-node=x where x=16 is a good starting point
* performance expectations are that with a single node and 1 cpu per task and 16 tasks per node we can run 20000 sampling_frame in 9 hours

#### amend the slurm script settings in mjob_run_cedar.sh
#Runbook info.

~~~
#!/bin/bash
# example slurm job script setup to run on for example Cedar
#SBATCH --job-name=SLURM_imp
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --cpus-per-task=1
#SBATCH --mem=32G
#SBATCH --time=0-01:00:00
#SBATCH --account=sponsername 
~~~


#in order to run the job we call this and give a unit number to be used for naming the folder that is setup eg: 12 here
~~~
./mjob_run_cedar.sh 12
~~~

The wrapper script mjob_run_cedar.sh essentially performs a slurm job scheduler call to launch: srun python prep_hyperp_imp_v2ux.py and this in turn runs the 
prep_hyperp_imp_v2ux.py driver script. The configuration of the driver script is accomplished with the ConfigImp.yaml
There are assumptions that have been made and while a basic modeling run has been anticipated. The prep_hyperp_imp_v2ux.py script can
be customised further in order to fit the specific modeling scenario.

```
finished
```

End with an example of getting some data out of the system or using it for a little demo

## Running the tests

Explain how to run the automated tests for this system

### Break down into end to end tests

Explain the purpose of these tests and why they are performed.

```
Give an example
```

### And coding style tests

Explain what these tests test and why

```
Give an example
```

## Deployment

Add additional notes about how to deploy this on a live system

## Built With

* [Python](https://github.com/pellst/imp_msstudio_init) - The language used
* [IMP](https://integrativemodeling.org/tutorials/rnapolii_stalk/) - The integrated modeling platform 

## Contributing

Please read [CONTRIBUTING.md] for details on our code of conduct, and the process for submitting pull requests to us.

## Versioning

We use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags). 

## Authors

* **MassSpecStudio Development Team** - *Initial work* - [University of Calgary](https://github.com/pellst/imp_msstudio_init)

See also the list of [contributors](https://github.com/pellst/imp_msstudio_init/contributors) who participated in this project.

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* [MassSpecStudio Development Team](https://www.msstudio.ca/mss-improv/)
* [IMP dataset source](https://integrativemodeling.org/tutorials/rnapolii_stalk/)
* Inspiration
* etc

